{
  "ten": {
    "log": {
      "handlers": [
        {
          "matchers": [
            {
              "level": "debug"
            }
          ],
          "formatter": {
            "type": "plain",
            "colored": false
          },
          "emitter": {
            "type": "console",
            "config": {
              "stream": "stdout"
            }
          }
        }
      ]
    },
    "predefined_graphs": [
      {
        "name": "voice_assistant",
        "auto_start": false,
        "graph": {
          "nodes": [
            {
              "type": "extension",
              "name": "agora_rtc",
              "addon": "agora_rtc",
              "extension_group": "default",
              "property": {
                "app_id": "${env:AGORA_APP_ID}",
                "app_certificate": "${env:AGORA_APP_CERTIFICATE|}",
                "channel": "ten_agent_test",
                "stream_id": 1234,
                "remote_stream_id": 123,
                "subscribe_audio": true,
                "publish_audio": true,
                "publish_data": true,
                "enable_agora_asr": false
              }
            },
            {
              "type": "extension",
              "name": "stt",
              "addon": "deepgram_ws_asr_python",
              "extension_group": "stt",
              "property": {
                "params": {
                  "api_key": "${env:DEEPGRAM_API_KEY}",
                  "url": "wss://api.deepgram.com/v2/listen",
                  "model": "flux-general-en",
                  "language": "en-US",
                  "interim_results": true,
                  "eot_threshold": 0.9,
                  "eot_timeout_ms": 2000,
                  "min_interim_confidence": 0.75
                }
              }
            },
            {
              "type": "extension",
              "name": "llm",
              "addon": "openai_llm2_python",
              "extension_group": "chatgpt",
              "property": {
                "base_url": "https://api.openai.com/v1",
                "api_key": "${env:OPENAI_API_KEY}",
                "frequency_penalty": 0.9,
                "model": "${env:OPENAI_MODEL}",
                "max_tokens": 512,
                "prompt": "You are a voice assistant. Your responses will be heard, not read. Keep every response between 10-20 words.",
                "proxy_url": "${env:OPENAI_PROXY_URL|}",
                "greeting": "TEN Agent connected. How can I help you today?",
                "max_memory_length": 10
              }
            },
            {
              "type": "extension",
              "name": "tts",
              "addon": "elevenlabs_tts2_python",
              "extension_group": "tts",
              "property": {
                "dump": false,
                "dump_path": "./",
                "params": {
                  "key": "${env:ELEVENLABS_TTS_KEY}",
                  "model_id": "eleven_multilingual_v2",
                  "voice_id": "pNInz6obpgDQGcFmaJgB",
                  "output_format": "pcm_16000"
                }
              }
            },
            {
              "type": "extension",
              "name": "main_control",
              "addon": "main_python",
              "extension_group": "control",
              "property": {
                "greeting": "TEN Agent connected. How can I help you today?"
              }
            },
            {
              "type": "extension",
              "name": "message_collector",
              "addon": "message_collector2",
              "extension_group": "transcriber",
              "property": {}
            },
            {
              "type": "extension",
              "name": "weatherapi_tool_python",
              "addon": "weatherapi_tool_python",
              "extension_group": "default",
              "property": {
                "api_key": "${env:WEATHERAPI_API_KEY|}"
              }
            },
            {
              "type": "extension",
              "name": "streamid_adapter",
              "addon": "streamid_adapter",
              "property": {}
            }
          ],
          "connections": [
            {
              "extension": "main_control",
              "cmd": [
                {
                  "names": [
                    "on_user_joined",
                    "on_user_left"
                  ],
                  "source": [
                    {
                      "extension": "agora_rtc"
                    }
                  ]
                },
                {
                  "names": [
                    "tool_register"
                  ],
                  "source": [
                    {
                      "extension": "weatherapi_tool_python"
                    }
                  ]
                }
              ],
              "data": [
                {
                  "name": "asr_result",
                  "source": [
                    {
                      "extension": "stt"
                    }
                  ]
                }
              ]
            },
            {
              "extension": "agora_rtc",
              "audio_frame": [
                {
                  "name": "pcm_frame",
                  "dest": [
                    {
                      "extension": "streamid_adapter"
                    }
                  ]
                },
                {
                  "name": "pcm_frame",
                  "source": [
                    {
                      "extension": "tts"
                    }
                  ]
                }
              ],
              "data": [
                {
                  "name": "data",
                  "source": [
                    {
                      "extension": "message_collector"
                    }
                  ]
                }
              ]
            },
            {
              "extension": "streamid_adapter",
              "audio_frame": [
                {
                  "name": "pcm_frame",
                  "dest": [
                    {
                      "extension": "stt"
                    }
                  ]
                }
              ]
            },
            {
              "extension": "thymia_analyzer",
              "data": [
                {
                  "name": "tts_audio_start",
                  "source": [
                    {
                      "extension": "tts"
                    }
                  ]
                },
                {
                  "name": "tts_audio_end",
                  "source": [
                    {
                      "extension": "tts"
                    }
                  ]
                }
              ]
            }
          ]
        }
      },
      {
        "name": "voice_assistant_heygen",
        "auto_start": false,
        "graph": {
          "nodes": [
            {
              "type": "extension",
              "name": "agora_rtc",
              "addon": "agora_rtc",
              "extension_group": "default",
              "property": {
                "app_id": "${env:AGORA_APP_ID}",
                "app_certificate": "${env:AGORA_APP_CERTIFICATE|}",
                "channel": "",
                "stream_id": 0,
                "remote_stream_id": 182837,
                "subscribe_audio": true,
                "publish_audio": true,
                "publish_data": true,
                "enable_agora_asr": false
              }
            },
            {
              "type": "extension",
              "name": "stt",
              "addon": "deepgram_asr_python",
              "extension_group": "stt",
              "property": {
                "params": {
                  "api_key": "${env:DEEPGRAM_API_KEY}",
                  "language": "en-US",
                  "model": "nova-3"
                }
              }
            },
            {
              "type": "extension",
              "name": "llm",
              "addon": "openai_llm2_python",
              "extension_group": "chatgpt",
              "property": {
                "base_url": "https://api.openai.com/v1",
                "api_key": "${env:OPENAI_API_KEY}",
                "frequency_penalty": 0.9,
                "model": "${env:OPENAI_MODEL}",
                "max_tokens": 512,
                "prompt": "",
                "proxy_url": "${env:OPENAI_PROXY_URL|}",
                "greeting": "TEN Agent connected. How can I help you today?",
                "max_memory_length": 10
              }
            },
            {
              "type": "extension",
              "name": "tts",
              "addon": "elevenlabs_tts2_python",
              "extension_group": "tts",
              "property": {
                "dump": false,
                "dump_path": "./",
                "params": {
                  "key": "${env:ELEVENLABS_TTS_KEY}",
                  "model_id": "eleven_multilingual_v2",
                  "voice_id": "pNInz6obpgDQGcFmaJgB",
                  "output_format": "pcm_16000"
                }
              }
            },
            {
              "type": "extension",
              "name": "main_control",
              "addon": "main_python",
              "extension_group": "control",
              "property": {
                "greeting": "TEN Agent connected. How can I help you today?"
              }
            },
            {
              "type": "extension",
              "name": "message_collector",
              "addon": "message_collector2",
              "extension_group": "transcriber",
              "property": {}
            },
            {
              "type": "extension",
              "name": "weatherapi_tool_python",
              "addon": "weatherapi_tool_python",
              "extension_group": "default",
              "property": {
                "api_key": "${env:WEATHERAPI_API_KEY|}"
              }
            },
            {
              "type": "extension",
              "name": "streamid_adapter",
              "addon": "streamid_adapter",
              "property": {}
            },
            {
              "type": "extension",
              "name": "avatar",
              "addon": "heygen_avatar_python",
              "extension_group": "default",
              "property": {
                "heygen_api_key": "${env:HEYGEN_API_KEY|}",
                "agora_appid": "${env:AGORA_APP_ID}",
                "agora_appcert": "${env:AGORA_APP_CERTIFICATE|}",
                "channel": "",
                "agora_avatar_uid": 12345,
                "input_audio_sample_rate": 16000
              }
            }
          ],
          "connections": [
            {
              "extension": "main_control",
              "cmd": [
                {
                  "names": [
                    "on_user_joined",
                    "on_user_left"
                  ],
                  "source": [
                    {
                      "extension": "agora_rtc"
                    }
                  ]
                },
                {
                  "names": [
                    "tool_register"
                  ],
                  "source": [
                    {
                      "extension": "weatherapi_tool_python"
                    }
                  ]
                }
              ],
              "data": [
                {
                  "name": "asr_result",
                  "source": [
                    {
                      "extension": "stt"
                    }
                  ]
                }
              ]
            },
            {
              "extension": "agora_rtc",
              "audio_frame": [
                {
                  "name": "pcm_frame",
                  "dest": [
                    {
                      "extension": "streamid_adapter"
                    }
                  ]
                }
              ],
              "data": [
                {
                  "name": "data",
                  "source": [
                    {
                      "extension": "message_collector"
                    }
                  ]
                }
              ]
            },
            {
              "extension": "streamid_adapter",
              "audio_frame": [
                {
                  "name": "pcm_frame",
                  "dest": [
                    {
                      "extension": "stt"
                    }
                  ]
                }
              ]
            },
            {
              "extension": "tts",
              "cmd": [
                {
                  "name": "flush",
                  "dest": [
                    {
                      "extension": "avatar"
                    }
                  ]
                }
              ],
              "audio_frame": [
                {
                  "name": "pcm_frame",
                  "dest": [
                    {
                      "extension": "avatar"
                    }
                  ]
                }
              ],
              "data": [
                {
                  "name": "tts_audio_end",
                  "dest": [
                    {
                      "extension": "avatar"
                    }
                  ]
                }
              ]
            }
          ]
        }
      },
      {
        "name": "voice_assistant_generic_video",
        "auto_start": false,
        "graph": {
          "nodes": [
            {
              "type": "extension",
              "name": "agora_rtc",
              "addon": "agora_rtc",
              "extension_group": "default",
              "property": {
                "app_id": "${env:AGORA_APP_ID}",
                "app_certificate": "${env:AGORA_APP_CERTIFICATE|}",
                "channel": "ten_agent_test",
                "stream_id": 1234,
                "remote_stream_id": 123,
                "subscribe_audio": true,
                "publish_audio": true,
                "publish_data": true,
                "enable_agora_asr": false
              }
            },
            {
              "type": "extension",
              "name": "stt",
              "addon": "deepgram_asr_python",
              "extension_group": "stt",
              "property": {
                "params": {
                  "api_key": "${env:DEEPGRAM_API_KEY}",
                  "language": "en-US",
                  "model": "nova-3"
                }
              }
            },
            {
              "type": "extension",
              "name": "llm",
              "addon": "openai_llm2_python",
              "extension_group": "chatgpt",
              "property": {
                "base_url": "https://api.openai.com/v1",
                "api_key": "${env:OPENAI_API_KEY}",
                "frequency_penalty": 0.9,
                "model": "${env:OPENAI_MODEL}",
                "max_tokens": 512,
                "prompt": "",
                "proxy_url": "${env:OPENAI_PROXY_URL|}",
                "greeting": "TEN Agent connected. How can I help you today?",
                "max_memory_length": 10
              }
            },
            {
              "type": "extension",
              "name": "tts",
              "addon": "elevenlabs_tts2_python",
              "extension_group": "tts",
              "property": {
                "dump": false,
                "dump_path": "./",
                "params": {
                  "key": "${env:ELEVENLABS_TTS_KEY}",
                  "model_id": "eleven_multilingual_v2",
                  "voice_id": "pNInz6obpgDQGcFmaJgB",
                  "output_format": "pcm_16000"
                }
              }
            },
            {
              "type": "extension",
              "name": "main_control",
              "addon": "main_python",
              "extension_group": "control",
              "property": {
                "greeting": "TEN Agent connected. How can I help you today?"
              }
            },
            {
              "type": "extension",
              "name": "message_collector",
              "addon": "message_collector2",
              "extension_group": "transcriber",
              "property": {}
            },
            {
              "type": "extension",
              "name": "weatherapi_tool_python",
              "addon": "weatherapi_tool_python",
              "extension_group": "default",
              "property": {
                "api_key": "${env:WEATHERAPI_API_KEY|}"
              }
            },
            {
              "type": "extension",
              "name": "streamid_adapter",
              "addon": "streamid_adapter",
              "property": {}
            },
            {
              "type": "extension",
              "name": "avatar",
              "addon": "generic_video_python",
              "extension_group": "default",
              "property": {
                "generic_video_api_key": "${env:GENERIC_VIDEO_API_KEY|}",
                "agora_appid": "${env:AGORA_APP_ID}",
                "agora_appcert": "${env:AGORA_APP_CERTIFICATE|}",
                "agora_channel_name": "agora_rqkxw1",
                "agora_video_uid": 12345,
                "avatar_id": "16cb73e7de08",
                "quality": "high",
                "version": "v1",
                "video_encoding": "H264",
                "enable_string_uid": false,
                "activity_idle_timeout": 60,
                "start_endpoint": "https://api.example.com/v1/sessions/start",
                "stop_endpoint": "https://api.example.com/v1/sessions/stop",
                "input_audio_sample_rate": 16000
              }
            }
          ],
          "connections": [
            {
              "extension": "main_control",
              "cmd": [
                {
                  "names": [
                    "on_user_joined",
                    "on_user_left"
                  ],
                  "source": [
                    {
                      "extension": "agora_rtc"
                    }
                  ]
                },
                {
                  "names": [
                    "tool_register"
                  ],
                  "source": [
                    {
                      "extension": "weatherapi_tool_python"
                    }
                  ]
                }
              ],
              "data": [
                {
                  "name": "asr_result",
                  "source": [
                    {
                      "extension": "stt"
                    }
                  ]
                }
              ]
            },
            {
              "extension": "agora_rtc",
              "audio_frame": [
                {
                  "name": "pcm_frame",
                  "dest": [
                    {
                      "extension": "streamid_adapter"
                    }
                  ]
                }
              ],
              "data": [
                {
                  "name": "data",
                  "source": [
                    {
                      "extension": "message_collector"
                    }
                  ]
                }
              ]
            },
            {
              "extension": "streamid_adapter",
              "audio_frame": [
                {
                  "name": "pcm_frame",
                  "dest": [
                    {
                      "extension": "stt"
                    }
                  ]
                }
              ]
            },
            {
              "extension": "tts",
              "cmd": [
                {
                  "name": "flush",
                  "dest": [
                    {
                      "extension": "avatar"
                    }
                  ]
                }
              ],
              "audio_frame": [
                {
                  "name": "pcm_frame",
                  "dest": [
                    {
                      "extension": "avatar"
                    }
                  ]
                }
              ],
              "data": [
                {
                  "name": "tts_audio_end",
                  "dest": [
                    {
                      "extension": "avatar"
                    }
                  ]
                }
              ]
            }
          ]
        }
      },
      {
        "name": "flux_thymia_heygen_cartesia",
        "auto_start": false,
        "graph": {
          "nodes": [
            {
              "type": "extension",
              "name": "agora_rtc",
              "addon": "agora_rtc",
              "extension_group": "default",
              "property": {
                "app_id": "${env:AGORA_APP_ID}",
                "app_certificate": "${env:AGORA_APP_CERTIFICATE|}",
                "channel": "",
                "stream_id": 1234,
                "remote_stream_id": 123,
                "subscribe_audio": true,
                "publish_audio": true,
                "publish_data": true,
                "enable_agora_asr": false
              }
            },
            {
              "type": "extension",
              "name": "stt",
              "addon": "deepgram_ws_asr_python",
              "extension_group": "stt",
              "property": {
                "params": {
                  "api_key": "${env:DEEPGRAM_API_KEY}",
                  "url": "wss://api.deepgram.com/v2/listen",
                  "model": "flux-general-en",
                  "language": "en-US",
                  "interim_results": true,
                  "eot_threshold": 0.9,
                  "eot_timeout_ms": 2000,
                  "min_interim_confidence": 0.75
                }
              }
            },
            {
              "type": "extension",
              "name": "llm",
              "addon": "openai_llm2_python",
              "extension_group": "chatgpt",
              "property": {
                "base_url": "https://api.openai.com/v1",
                "api_key": "${env:OPENAI_API_KEY}",
                "frequency_penalty": 0.9,
                "model": "${env:OPENAI_MODEL}",
                "max_tokens": 512,
                "prompt": "You are a brief, friendly wellness assistant. WORKFLOW: 1) First, ask for their name, date of birth, and birth sex. 2) Once collected, call set_user_info(name, date_of_birth, birth_sex). 3) Then engage with SHORT questions (max 15 words) about their day, hobbies, interests to gather 22s+ speech. 4) After 22s, check get_wellness_metrics. If user asks about progress, share the collection status (e.g., 'We've collected 15 seconds so far, need 7 more'). Otherwise, continue conversation naturally. 5) When available (status='available'), present results. Wellness scale: 0-1 (0=low/none, 0.5=moderate, 1.0=high). Keep responses brief except when presenting full stats. IMPORTANT: Use plain text only - do not use markdown formatting like ** or __ in responses. IMPORTANT: You MUST start EVERY response with Cartesia SSML control tags <speed ratio=\"1.0\"/><volume ratio=\"1.0\"/><emotion value=\"neutral\"/> before your text. Speed ratio: 0.6 (slow) to 1.5 (fast), default 1.0. Volume ratio: 0.5 (quiet) to 2.0 (loud), default 1.0. Emotions: neutral, angry, excited, content, sad, sympathetic, scared. Add [laughter] where appropriate. Example: <speed ratio=\"1.2\"/><volume ratio=\"1.3\"/><emotion value=\"excited\"/>Oh wow, Valentine's Day snuck up on you, huh? [laughter] Don't worry\u2014we'll get you a table, no problem! Let's make it special.",
                "proxy_url": "${env:OPENAI_PROXY_URL|}",
                "greeting": "Hi! I'm your wellness assistant. To start, what's your name?",
                "max_memory_length": 10
              }
            },
            {
              "type": "extension",
              "name": "tts",
              "addon": "cartesia_tts",
              "extension_group": "tts",
              "property": {
                "dump": false,
                "dump_path": "./",
                "params": {
                  "api_key": "${env:CARTESIA_TTS_KEY}",
                  "model_id": "sonic-3",
                  "voice": {
                    "mode": "id",
                    "id": "cbaf8084-f009-4838-a096-07ee2e6612b1"
                  },
                  "generation_config": {
                    "speed": 1.2
                  },
                  "output_format": {
                    "container": "raw",
                    "sample_rate": 44100
                  },
                  "language": "en"
                }
              }
            },
            {
              "type": "extension",
              "name": "main_control",
              "addon": "main_python",
              "extension_group": "control",
              "property": {
                "greeting": "Hi! I'm your wellness assistant. To start, what's your name?"
              }
            },
            {
              "type": "extension",
              "name": "message_collector",
              "addon": "message_collector2",
              "extension_group": "transcriber",
              "property": {}
            },
            {
              "type": "extension",
              "name": "weatherapi_tool_python",
              "addon": "weatherapi_tool_python",
              "extension_group": "default",
              "property": {
                "api_key": "${env:WEATHERAPI_API_KEY|}"
              }
            },
            {
              "type": "extension",
              "name": "thymia_analyzer",
              "addon": "thymia_analyzer_python",
              "extension_group": "default",
              "property": {
                "api_key": "${env:THYMIA_API_KEY|}",
                "min_speech_duration": 30,
                "silence_threshold": 0.02,
                "continuous_analysis": true,
                "min_interval_seconds": 60,
                "max_analyses_per_session": 10,
                "poll_timeout": 60,
                "poll_interval": 5
              }
            },
            {
              "type": "extension",
              "name": "streamid_adapter",
              "addon": "streamid_adapter",
              "property": {}
            },
            {
              "type": "extension",
              "name": "avatar",
              "addon": "heygen_avatar_python",
              "extension_group": "default",
              "property": {
                "heygen_api_key": "${env:HEYGEN_API_KEY|}",
                "agora_appid": "${env:AGORA_APP_ID}",
                "agora_appcert": "${env:AGORA_APP_CERTIFICATE|}",
                "channel": "",
                "agora_avatar_uid": 12345,
                "input_audio_sample_rate": 44100,
                "avatar_name": "Katya_Chair_Sitting_public"
              }
            }
          ],
          "connections": [
            {
              "extension": "main_control",
              "cmd": [
                {
                  "names": [
                    "on_user_joined",
                    "on_user_left"
                  ],
                  "source": [
                    {
                      "extension": "agora_rtc"
                    }
                  ]
                },
                {
                  "names": [
                    "tool_register"
                  ],
                  "source": [
                    {
                      "extension": "weatherapi_tool_python"
                    },
                    {
                      "extension": "thymia_analyzer"
                    }
                  ]
                }
              ],
              "data": [
                {
                  "name": "asr_result",
                  "source": [
                    {
                      "extension": "stt"
                    }
                  ]
                },
                {
                  "name": "text_data",
                  "source": [
                    {
                      "extension": "thymia_analyzer"
                    }
                  ]
                }
              ]
            },
            {
              "extension": "agora_rtc",
              "audio_frame": [
                {
                  "name": "pcm_frame",
                  "dest": [
                    {
                      "extension": "streamid_adapter"
                    },
                    {
                      "extension": "thymia_analyzer"
                    }
                  ]
                }
              ],
              "data": [
                {
                  "name": "data",
                  "source": [
                    {
                      "extension": "message_collector"
                    }
                  ]
                }
              ]
            },
            {
              "extension": "streamid_adapter",
              "audio_frame": [
                {
                  "name": "pcm_frame",
                  "dest": [
                    {
                      "extension": "stt"
                    }
                  ]
                }
              ]
            },
            {
              "extension": "tts",
              "cmd": [
                {
                  "name": "flush",
                  "dest": [
                    {
                      "extension": "avatar"
                    }
                  ]
                }
              ],
              "audio_frame": [
                {
                  "name": "pcm_frame",
                  "dest": [
                    {
                      "extension": "avatar"
                    }
                  ]
                }
              ],
              "data": [
                {
                  "name": "tts_audio_end",
                  "dest": [
                    {
                      "extension": "avatar"
                    }
                  ]
                }
              ]
            }
          ]
        }
      },
      {
        "name": "flux_apollo_cartesia",
        "auto_start": false,
        "graph": {
          "nodes": [
            {
              "type": "extension",
              "name": "agora_rtc",
              "addon": "agora_rtc",
              "extension_group": "default",
              "property": {
                "app_id": "${env:AGORA_APP_ID}",
                "app_certificate": "${env:AGORA_APP_CERTIFICATE|}",
                "channel": "",
                "stream_id": 0,
                "remote_stream_id": 182837,
                "subscribe_audio": true,
                "publish_audio": true,
                "publish_data": true,
                "enable_agora_asr": false
              }
            },
            {
              "type": "extension",
              "name": "stt",
              "addon": "deepgram_ws_asr_python",
              "extension_group": "stt",
              "property": {
                "params": {
                  "api_key": "${env:DEEPGRAM_API_KEY}",
                  "url": "wss://api.deepgram.com/v2/listen",
                  "model": "flux-general-en",
                  "language": "en-US",
                  "interim_results": true,
                  "eot_threshold": 0.9,
                  "eot_timeout_ms": 2000,
                  "min_interim_confidence": 0.75
                }
              }
            },
            {
              "type": "extension",
              "name": "llm",
              "addon": "openai_llm2_python",
              "extension_group": "chatgpt",
              "property": {
                "base_url": "https://api.openai.com/v1",
                "api_key": "${env:OPENAI_API_KEY}",
                "frequency_penalty": 0.9,
                "model": "${env:OPENAI_MODEL}",
                "max_tokens": 200,
                "prompt": "You are a mental wellness research assistant conducting a demonstration. Guide the conversation efficiently:\n\n1. When user provides their name, sex, and year of birth, acknowledge warmly in 1-2 sentences and ask about their day. Keep this response SHORT and conversational. DO NOT call set_user_info yet.\n2. On your NEXT response (after they answer about their day), silently call set_user_info(name, year_of_birth, birth_sex) in the background while continuing the conversation. This is REQUIRED before analysis can start.\n3. Ask: 'Tell me about your interests and hobbies.' (wait for response - aim for 30+ seconds total speech)\n4. CRITICAL: Before moving to reading phase or saying you're processing, you MUST call check_phase_progress to verify enough speech has been collected. If phase_complete=false, ask another question to gather more speech. Only proceed when phase_complete=true.\n5. Once check_phase_progress confirms phase_complete=true, say: 'Thank you. Now please read aloud anything you can see around you - a book, article, or text on your screen - for about 30 seconds.'\n6. CRITICAL: After user finishes reading, you MUST call check_phase_progress again before saying you're processing. If reading_phase_complete=false, ask them to continue reading. Only when reading_phase_complete=true, say: 'Perfect. I'm processing your responses now, this will take about a minute.'\n7. IMPORTANT: You will receive TWO separate [SYSTEM ALERT] messages - one for wellness metrics, then another for clinical indicators. WAIT for each alert before announcing.\n8. When you receive '[SYSTEM ALERT] Wellness metrics ready', call get_wellness_metrics and announce the 5 wellness metrics (stress, distress, burnout, fatigue, low_self_esteem). Values are PERCENTAGES 0-100. DO NOT use markdown formatting (no **, *, _, etc.) - use plain numbered lists only. After announcing, IMMEDIATELY call confirm_announcement with phase='hellos'. Then WAIT - do NOT proactively call get_wellness_metrics again.\n9. Later, you will receive '[SYSTEM ALERT] Clinical indicators ready'. Only then should you call get_wellness_metrics again and announce the 2 clinical indicators (depression, anxiety). After announcing, IMMEDIATELY call confirm_announcement with phase='apollo'.\n10. Frame as research indicators, not clinical diagnosis\n11. Thank them for participating in the demonstration\n\nNote: Keep all responses concise. We need 60 seconds total speech (30s for mood/interests + 30s for reading). The first 30s is used for both Hellos and Apollo mood analysis. The next 30s is used for Apollo reading analysis.",
                "proxy_url": "${env:OPENAI_PROXY_URL|}",
                "greeting": "Hi there! I would like to talk to you for a couple of minutes and use your voice to predict your mood and energy levels including any depression, anxiety, stress, and fatigue. Nothing will be recorded and this is purely a demonstration of what is possible now that we have trained our models with many hours of professionally labelled data. Please begin by telling me your name, sex and year of birth.",
                "max_memory_length": 10
              }
            },
            {
              "type": "extension",
              "name": "tts",
              "addon": "cartesia_tts",
              "extension_group": "tts",
              "property": {
                "dump": false,
                "dump_path": "./",
                "params": {
                  "api_key": "${env:CARTESIA_TTS_KEY}",
                  "model_id": "sonic-3",
                  "voice": {
                    "mode": "id",
                    "id": "71a7ad14-091c-4e8e-a314-022ece01c121"
                  },
                  "generation_config": {
                    "speed": 1.0
                  },
                  "output_format": {
                    "container": "raw",
                    "sample_rate": 44100
                  },
                  "language": "en"
                }
              }
            },
            {
              "type": "extension",
              "name": "thymia_analyzer",
              "addon": "thymia_analyzer_python",
              "extension_group": "default",
              "property": {
                "api_key": "${env:THYMIA_API_KEY}",
                "min_speech_duration": 30.0,
                "analysis_mode": "demo_dual",
                "apollo_mood_duration": 30.0,
                "apollo_read_duration": 30.0
              }
            },
            {
              "type": "extension",
              "name": "main_control",
              "addon": "main_python",
              "extension_group": "control",
              "property": {
                "greeting": "Hi there! I would like to talk to you for a couple of minutes and use your voice to predict your mood and energy levels including any depression, anxiety, stress, and fatigue. Nothing will be recorded and this is purely a demonstration of what is possible now that we have trained our models with many hours of professionally labelled data. Please begin by telling me your name, sex and year of birth."
              }
            },
            {
              "type": "extension",
              "name": "message_collector",
              "addon": "message_collector2",
              "extension_group": "transcriber",
              "property": {}
            },
            {
              "type": "extension",
              "name": "streamid_adapter",
              "addon": "streamid_adapter",
              "property": {}
            }
          ],
          "connections": [
            {
              "extension": "main_control",
              "cmd": [
                {
                  "names": [
                    "on_user_joined",
                    "on_user_left"
                  ],
                  "source": [
                    {
                      "extension": "agora_rtc"
                    }
                  ]
                },
                {
                  "names": [
                    "tool_register"
                  ],
                  "source": [
                    {
                      "extension": "thymia_analyzer"
                    }
                  ]
                }
              ],
              "data": [
                {
                  "name": "asr_result",
                  "source": [
                    {
                      "extension": "stt"
                    }
                  ]
                },
                {
                  "name": "text_data",
                  "source": [
                    {
                      "extension": "thymia_analyzer"
                    }
                  ]
                }
              ]
            },
            {
              "extension": "agora_rtc",
              "audio_frame": [
                {
                  "name": "pcm_frame",
                  "source": [
                    {
                      "extension": "tts"
                    }
                  ]
                },
                {
                  "name": "pcm_frame",
                  "dest": [
                    {
                      "extension": "streamid_adapter"
                    },
                    {
                      "extension": "thymia_analyzer"
                    }
                  ]
                }
              ],
              "data": [
                {
                  "name": "data",
                  "source": [
                    {
                      "extension": "message_collector"
                    }
                  ]
                }
              ]
            },
            {
              "extension": "streamid_adapter",
              "audio_frame": [
                {
                  "name": "pcm_frame",
                  "dest": [
                    {
                      "extension": "stt"
                    }
                  ]
                }
              ]
            }
          ]
        }
      },
      {
        "name": "nova3_apollo_cartesia",
        "auto_start": false,
        "graph": {
          "nodes": [
            {
              "type": "extension",
              "name": "agora_rtc",
              "addon": "agora_rtc",
              "extension_group": "default",
              "property": {
                "app_id": "${env:AGORA_APP_ID}",
                "app_certificate": "${env:AGORA_APP_CERTIFICATE|}",
                "channel": "",
                "stream_id": 0,
                "remote_stream_id": 182837,
                "subscribe_audio": true,
                "publish_audio": true,
                "publish_data": true,
                "enable_agora_asr": false
              }
            },
            {
              "type": "extension",
              "name": "stt",
              "addon": "deepgram_ws_asr_python",
              "extension_group": "stt",
              "property": {
                "params": {
                  "api_key": "${env:DEEPGRAM_API_KEY}",
                  "url": "wss://api.deepgram.com/v1/listen",
                  "model": "nova-3",
                  "language": "en-US",
                  "endpointing": 300,
                  "utterance_end_ms": 1000
                }
              }
            },
            {
              "type": "extension",
              "name": "llm",
              "addon": "openai_llm2_python",
              "extension_group": "chatgpt",
              "property": {
                "base_url": "https://api.openai.com/v1",
                "api_key": "${env:OPENAI_API_KEY}",
                "frequency_penalty": 0.9,
                "model": "${env:OPENAI_MODEL}",
                "max_tokens": 200,
                "prompt": "You are a mental wellness research assistant conducting a demonstration. Guide the conversation efficiently:\n\n1. When user provides their name, sex, and year of birth, acknowledge warmly in 1-2 sentences and ask about their day. Keep this response SHORT and conversational. DO NOT call set_user_info yet.\n2. On your NEXT response (after they answer about their day), silently call set_user_info(name, year_of_birth, birth_sex) in the background while continuing the conversation. This is REQUIRED before analysis can start.\n3. Ask: 'Tell me about your interests and hobbies.' (wait for response - aim for 30+ seconds total speech)\n4. CRITICAL: Before moving to reading phase or saying you're processing, you MUST call check_phase_progress to verify enough speech has been collected. If phase_complete=false, ask another question to gather more speech. Only proceed when phase_complete=true.\n5. Once check_phase_progress confirms phase_complete=true, say: 'Thank you. Now please read aloud anything you can see around you - a book, article, or text on your screen - for about 30 seconds.'\n6. CRITICAL: After user finishes reading, you MUST call check_phase_progress again before saying you're processing. If reading_phase_complete=false, ask them to continue reading. Only when reading_phase_complete=true, say: 'Perfect. I'm processing your responses now, this will take about a minute.'\n7. IMPORTANT: You will receive TWO separate [SYSTEM ALERT] messages - one for wellness metrics, then another for clinical indicators. WAIT for each alert before announcing.\n8. When you receive '[SYSTEM ALERT] Wellness metrics ready', call get_wellness_metrics and announce the 5 wellness metrics (stress, distress, burnout, fatigue, low_self_esteem). Values are PERCENTAGES 0-100. DO NOT use markdown formatting (no **, *, _, etc.) - use plain numbered lists only. After announcing, IMMEDIATELY call confirm_announcement with phase='hellos'. Then WAIT - do NOT proactively call get_wellness_metrics again.\n9. Later, you will receive '[SYSTEM ALERT] Clinical indicators ready'. Only then should you call get_wellness_metrics again and announce the 2 clinical indicators (depression, anxiety). After announcing, IMMEDIATELY call confirm_announcement with phase='apollo'.\n10. Frame as research indicators, not clinical diagnosis\n11. Thank them for participating in the demonstration\n\nNote: Keep all responses concise. We need 60 seconds total speech (30s for mood/interests + 30s for reading). The first 30s is used for both Hellos and Apollo mood analysis. The next 30s is used for Apollo reading analysis.",
                "proxy_url": "${env:OPENAI_PROXY_URL|}",
                "greeting": "Hi there! I would like to talk to you for a couple of minutes and use your voice to predict your mood and energy levels including any depression, anxiety, stress, and fatigue. Nothing will be recorded and this is purely a demonstration of what is possible now that we have trained our models with many hours of professionally labelled data. Please begin by telling me your name, sex and year of birth.",
                "max_memory_length": 10
              }
            },
            {
              "type": "extension",
              "name": "tts",
              "addon": "cartesia_tts",
              "extension_group": "tts",
              "property": {
                "dump": false,
                "dump_path": "./",
                "params": {
                  "api_key": "${env:CARTESIA_TTS_KEY}",
                  "model_id": "sonic-3",
                  "voice": {
                    "mode": "id",
                    "id": "71a7ad14-091c-4e8e-a314-022ece01c121"
                  },
                  "generation_config": {
                    "speed": 1.0
                  },
                  "output_format": {
                    "container": "raw",
                    "sample_rate": 44100
                  },
                  "language": "en"
                }
              }
            },
            {
              "type": "extension",
              "name": "thymia_analyzer",
              "addon": "thymia_analyzer_python",
              "extension_group": "default",
              "property": {
                "api_key": "${env:THYMIA_API_KEY}",
                "min_speech_duration": 30.0,
                "analysis_mode": "demo_dual",
                "apollo_mood_duration": 30.0,
                "apollo_read_duration": 30.0
              }
            },
            {
              "type": "extension",
              "name": "main_control",
              "addon": "main_python",
              "extension_group": "control",
              "property": {
                "greeting": "Hi there! I would like to talk to you for a couple of minutes and use your voice to predict your mood and energy levels including any depression, anxiety, stress, and fatigue. Nothing will be recorded and this is purely a demonstration of what is possible now that we have trained our models with many hours of professionally labelled data. Please begin by telling me your name, sex and year of birth."
              }
            },
            {
              "type": "extension",
              "name": "message_collector",
              "addon": "message_collector2",
              "extension_group": "transcriber",
              "property": {}
            },
            {
              "type": "extension",
              "name": "streamid_adapter",
              "addon": "streamid_adapter",
              "property": {}
            }
          ],
          "connections": [
            {
              "extension": "main_control",
              "cmd": [
                {
                  "names": [
                    "on_user_joined",
                    "on_user_left"
                  ],
                  "source": [
                    {
                      "extension": "agora_rtc"
                    }
                  ]
                },
                {
                  "names": [
                    "tool_register"
                  ],
                  "source": [
                    {
                      "extension": "thymia_analyzer"
                    }
                  ]
                }
              ],
              "data": [
                {
                  "name": "asr_result",
                  "source": [
                    {
                      "extension": "stt"
                    }
                  ]
                },
                {
                  "name": "text_data",
                  "source": [
                    {
                      "extension": "thymia_analyzer"
                    }
                  ]
                }
              ]
            },
            {
              "extension": "agora_rtc",
              "audio_frame": [
                {
                  "name": "pcm_frame",
                  "source": [
                    {
                      "extension": "tts"
                    }
                  ]
                },
                {
                  "name": "pcm_frame",
                  "dest": [
                    {
                      "extension": "streamid_adapter"
                    },
                    {
                      "extension": "thymia_analyzer"
                    }
                  ]
                }
              ],
              "data": [
                {
                  "name": "data",
                  "source": [
                    {
                      "extension": "message_collector"
                    }
                  ]
                }
              ]
            },
            {
              "extension": "streamid_adapter",
              "audio_frame": [
                {
                  "name": "pcm_frame",
                  "dest": [
                    {
                      "extension": "stt"
                    }
                  ]
                }
              ]
            }
          ]
        }
      },
      {
        "name": "flux_thymia_heygen_rime",
        "auto_start": false,
        "graph": {
          "nodes": [
            {
              "type": "extension",
              "name": "agora_rtc",
              "addon": "agora_rtc",
              "extension_group": "default",
              "property": {
                "app_id": "${env:AGORA_APP_ID}",
                "app_certificate": "${env:AGORA_APP_CERTIFICATE|}",
                "channel": "",
                "stream_id": 1234,
                "remote_stream_id": 123,
                "subscribe_audio": true,
                "publish_audio": true,
                "publish_data": true,
                "enable_agora_asr": false
              }
            },
            {
              "type": "extension",
              "name": "stt",
              "addon": "deepgram_ws_asr_python",
              "extension_group": "stt",
              "property": {
                "params": {
                  "api_key": "${env:DEEPGRAM_API_KEY}",
                  "url": "wss://api.deepgram.com/v2/listen",
                  "model": "flux-general-en",
                  "language": "en-US",
                  "interim_results": true,
                  "eot_threshold": 0.9,
                  "eot_timeout_ms": 2000,
                  "min_interim_confidence": 0.75
                }
              }
            },
            {
              "type": "extension",
              "name": "llm",
              "addon": "openai_llm2_python",
              "extension_group": "chatgpt",
              "property": {
                "base_url": "https://api.openai.com/v1",
                "api_key": "${env:OPENAI_API_KEY}",
                "frequency_penalty": 0.9,
                "model": "${env:OPENAI_MODEL}",
                "max_tokens": 512,
                "prompt": "You are a brief, friendly wellness assistant. WORKFLOW: 1) First, ask for their name, date of birth, and birth sex. 2) Once collected, call set_user_info(name, date_of_birth, birth_sex). 3) Then engage with SHORT questions (max 15 words) about their day, hobbies, interests to gather 22s+ speech. 4) After 22s, check get_wellness_metrics. If user asks about progress, share the collection status (e.g., 'We've collected 15 seconds so far, need 7 more'). Otherwise, continue conversation naturally. 5) When available (status='available'), present results. Wellness scale: 0-1 (0=low/none, 0.5=moderate, 1.0=high). Keep responses brief except when presenting full stats. IMPORTANT: Use plain text only - do not use markdown formatting like ** or __ in responses.",
                "proxy_url": "${env:OPENAI_PROXY_URL|}",
                "greeting": "Hi! I'm your wellness assistant. To start, what's your name?",
                "max_memory_length": 10
              }
            },
            {
              "type": "extension",
              "name": "tts",
              "addon": "rime_tts",
              "extension_group": "tts",
              "property": {
                "dump": false,
                "dump_path": "./",
                "params": {
                  "api_key": "${env:RIME_TTS_API_KEY}",
                  "speaker": "cove",
                  "modelId": "mistv2",
                  "lang": "eng",
                  "samplingRate": 16000,
                  "speedAlpha": 1
                }
              }
            },
            {
              "type": "extension",
              "name": "main_control",
              "addon": "main_python",
              "extension_group": "control",
              "property": {
                "greeting": "Hi! I'm your wellness assistant. To start, what's your name?"
              }
            },
            {
              "type": "extension",
              "name": "message_collector",
              "addon": "message_collector2",
              "extension_group": "transcriber",
              "property": {}
            },
            {
              "type": "extension",
              "name": "weatherapi_tool_python",
              "addon": "weatherapi_tool_python",
              "extension_group": "default",
              "property": {
                "api_key": "${env:WEATHERAPI_API_KEY|}"
              }
            },
            {
              "type": "extension",
              "name": "thymia_analyzer",
              "addon": "thymia_analyzer_python",
              "extension_group": "default",
              "property": {
                "api_key": "${env:THYMIA_API_KEY|}",
                "min_speech_duration": 30,
                "silence_threshold": 0.02,
                "continuous_analysis": true,
                "min_interval_seconds": 60,
                "max_analyses_per_session": 10,
                "poll_timeout": 60,
                "poll_interval": 5
              }
            },
            {
              "type": "extension",
              "name": "streamid_adapter",
              "addon": "streamid_adapter",
              "property": {}
            },
            {
              "type": "extension",
              "name": "avatar",
              "addon": "heygen_avatar_python",
              "extension_group": "default",
              "property": {
                "heygen_api_key": "${env:HEYGEN_API_KEY|}",
                "agora_appid": "${env:AGORA_APP_ID}",
                "agora_appcert": "${env:AGORA_APP_CERTIFICATE|}",
                "channel": "",
                "agora_avatar_uid": 12345,
                "input_audio_sample_rate": 16000,
                "avatar_name": "Katya_Chair_Sitting_public"
              }
            }
          ],
          "connections": [
            {
              "extension": "main_control",
              "cmd": [
                {
                  "names": [
                    "on_user_joined",
                    "on_user_left"
                  ],
                  "source": [
                    {
                      "extension": "agora_rtc"
                    }
                  ]
                },
                {
                  "names": [
                    "tool_register"
                  ],
                  "source": [
                    {
                      "extension": "weatherapi_tool_python"
                    },
                    {
                      "extension": "thymia_analyzer"
                    }
                  ]
                }
              ],
              "data": [
                {
                  "name": "asr_result",
                  "source": [
                    {
                      "extension": "stt"
                    }
                  ]
                },
                {
                  "name": "text_data",
                  "source": [
                    {
                      "extension": "thymia_analyzer"
                    }
                  ]
                }
              ]
            },
            {
              "extension": "agora_rtc",
              "audio_frame": [
                {
                  "name": "pcm_frame",
                  "dest": [
                    {
                      "extension": "streamid_adapter"
                    },
                    {
                      "extension": "thymia_analyzer"
                    }
                  ]
                }
              ],
              "data": [
                {
                  "name": "data",
                  "source": [
                    {
                      "extension": "message_collector"
                    }
                  ]
                }
              ]
            },
            {
              "extension": "streamid_adapter",
              "audio_frame": [
                {
                  "name": "pcm_frame",
                  "dest": [
                    {
                      "extension": "stt"
                    }
                  ]
                }
              ]
            },
            {
              "extension": "tts",
              "cmd": [
                {
                  "name": "flush",
                  "dest": [
                    {
                      "extension": "avatar"
                    }
                  ]
                }
              ],
              "audio_frame": [
                {
                  "name": "pcm_frame",
                  "dest": [
                    {
                      "extension": "avatar"
                    }
                  ]
                }
              ],
              "data": [
                {
                  "name": "tts_audio_end",
                  "dest": [
                    {
                      "extension": "avatar"
                    }
                  ]
                }
              ]
            }
          ]
        }
      },
      {
        "name": "flux_apollo_cartesia_heygen",
        "auto_start": false,
        "graph": {
          "nodes": [
            {
              "type": "extension",
              "name": "agora_rtc",
              "addon": "agora_rtc",
              "extension_group": "default",
              "property": {
                "app_id": "${env:AGORA_APP_ID}",
                "app_certificate": "${env:AGORA_APP_CERTIFICATE|}",
                "channel": "",
                "stream_id": 0,
                "remote_stream_id": 182837,
                "subscribe_audio": true,
                "publish_audio": true,
                "publish_data": true,
                "enable_agora_asr": false
              }
            },
            {
              "type": "extension",
              "name": "stt",
              "addon": "deepgram_ws_asr_python",
              "extension_group": "stt",
              "property": {
                "params": {
                  "api_key": "${env:DEEPGRAM_API_KEY}",
                  "url": "wss://api.deepgram.com/v2/listen",
                  "model": "flux-general-en",
                  "language": "en-US",
                  "interim_results": true,
                  "eot_threshold": 0.9,
                  "eot_timeout_ms": 2000,
                  "min_interim_confidence": 0.75
                }
              }
            },
            {
              "type": "extension",
              "name": "llm",
              "addon": "openai_llm2_python",
              "extension_group": "chatgpt",
              "property": {
                "base_url": "https://api.openai.com/v1",
                "api_key": "${env:OPENAI_API_KEY}",
                "frequency_penalty": 0.9,
                "model": "${env:OPENAI_MODEL}",
                "max_tokens": 200,
                "prompt": "You are a mental wellness research assistant conducting a demonstration. Guide the conversation efficiently:\n\n1. When user provides their name, sex, and year of birth, acknowledge warmly in 1-2 sentences and ask about their day. Keep this response SHORT and conversational. DO NOT call set_user_info yet.\n2. On your NEXT response (after they answer about their day), silently call set_user_info(name, year_of_birth, birth_sex) in the background while continuing the conversation. This is REQUIRED before analysis can start.\n3. Ask: 'Tell me about your interests and hobbies.' (wait for response - aim for 30+ seconds total speech)\n4. CRITICAL: Before moving to reading phase or saying you're processing, you MUST call check_phase_progress to verify enough speech has been collected. If phase_complete=false, ask another question to gather more speech. Only proceed when phase_complete=true.\n5. Once check_phase_progress confirms phase_complete=true, say: 'Thank you. Now please read aloud anything you can see around you - a book, article, or text on your screen - for about 30 seconds.'\n6. CRITICAL: After user finishes reading, you MUST call check_phase_progress again before saying you're processing. If reading_phase_complete=false, ask them to continue reading. Only when reading_phase_complete=true, say: 'Perfect. I'm processing your responses now, this will take about a minute.'\n7. IMPORTANT: You will receive TWO separate [SYSTEM ALERT] messages - one for wellness metrics, then another for clinical indicators. WAIT for each alert before announcing.\n8. When you receive '[SYSTEM ALERT] Wellness metrics ready', call get_wellness_metrics and announce the 5 wellness metrics (stress, distress, burnout, fatigue, low_self_esteem). Values are PERCENTAGES 0-100. DO NOT use markdown formatting (no **, *, _, etc.) - use plain numbered lists only. After announcing, IMMEDIATELY call confirm_announcement with phase='hellos'. Then WAIT - do NOT proactively call get_wellness_metrics again.\n9. Later, you will receive '[SYSTEM ALERT] Clinical indicators ready'. Only then should you call get_wellness_metrics again and announce the 2 clinical indicators (depression, anxiety). After announcing, IMMEDIATELY call confirm_announcement with phase='apollo'.\n10. Frame as research indicators, not clinical diagnosis\n11. Thank them for participating in the demonstration\n\nNote: Keep all responses concise. We need 60 seconds total speech (30s for mood/interests + 30s for reading). The first 30s is used for both Hellos and Apollo mood analysis. The next 30s is used for Apollo reading analysis.",
                "proxy_url": "${env:OPENAI_PROXY_URL|}",
                "greeting": "Hi there! I would like to talk to you for a couple of minutes and use your voice to predict your mood and energy levels including any depression, anxiety, stress, and fatigue. Nothing will be recorded and this is purely a demonstration of what is possible now that we have trained our models with many hours of professionally labelled data. Please begin by telling me your name, sex and year of birth.",
                "max_memory_length": 10
              }
            },
            {
              "type": "extension",
              "name": "tts",
              "addon": "cartesia_tts",
              "extension_group": "tts",
              "property": {
                "dump": false,
                "dump_path": "./",
                "params": {
                  "api_key": "${env:CARTESIA_TTS_KEY}",
                  "model_id": "sonic-3",
                  "voice": {
                    "mode": "id",
                    "id": "71a7ad14-091c-4e8e-a314-022ece01c121"
                  },
                  "generation_config": {
                    "speed": 1.0
                  },
                  "output_format": {
                    "container": "raw",
                    "sample_rate": 44100
                  },
                  "language": "en"
                }
              }
            },
            {
              "type": "extension",
              "name": "thymia_analyzer",
              "addon": "thymia_analyzer_python",
              "extension_group": "default",
              "property": {
                "api_key": "${env:THYMIA_API_KEY}",
                "min_speech_duration": 30.0,
                "analysis_mode": "demo_dual",
                "apollo_mood_duration": 30.0,
                "apollo_read_duration": 30.0
              }
            },
            {
              "type": "extension",
              "name": "avatar",
              "addon": "heygen_avatar_python",
              "extension_group": "default",
              "property": {
                "heygen_api_key": "${env:HEYGEN_API_KEY|}",
                "agora_appid": "${env:AGORA_APP_ID}",
                "agora_appcert": "${env:AGORA_APP_CERTIFICATE|}",
                "channel": "",
                "agora_avatar_uid": 12345,
                "input_audio_sample_rate": 44100,
                "avatar_name": "Katya_Chair_Sitting_public"
              }
            },
            {
              "type": "extension",
              "name": "main_control",
              "addon": "main_python",
              "extension_group": "control",
              "property": {
                "greeting": "Hi there! I would like to talk to you for a couple of minutes and use your voice to predict your mood and energy levels including any depression, anxiety, stress, and fatigue. Nothing will be recorded and this is purely a demonstration of what is possible now that we have trained our models with many hours of professionally labelled data. Please begin by telling me your name, sex and year of birth."
              }
            },
            {
              "type": "extension",
              "name": "message_collector",
              "addon": "message_collector2",
              "extension_group": "transcriber",
              "property": {}
            },
            {
              "type": "extension",
              "name": "streamid_adapter",
              "addon": "streamid_adapter",
              "property": {}
            }
          ],
          "connections": [
            {
              "extension": "main_control",
              "cmd": [
                {
                  "names": [
                    "on_user_joined",
                    "on_user_left"
                  ],
                  "source": [
                    {
                      "extension": "agora_rtc"
                    }
                  ]
                },
                {
                  "names": [
                    "tool_register"
                  ],
                  "source": [
                    {
                      "extension": "thymia_analyzer"
                    }
                  ]
                }
              ],
              "data": [
                {
                  "name": "asr_result",
                  "source": [
                    {
                      "extension": "stt"
                    }
                  ]
                },
                {
                  "name": "text_data",
                  "source": [
                    {
                      "extension": "thymia_analyzer"
                    }
                  ]
                }
              ]
            },
            {
              "extension": "agora_rtc",
              "audio_frame": [
                {
                  "name": "pcm_frame",
                  "dest": [
                    {
                      "extension": "streamid_adapter"
                    },
                    {
                      "extension": "thymia_analyzer"
                    }
                  ]
                }
              ],
              "data": [
                {
                  "name": "data",
                  "source": [
                    {
                      "extension": "message_collector"
                    }
                  ]
                }
              ]
            },
            {
              "extension": "streamid_adapter",
              "audio_frame": [
                {
                  "name": "pcm_frame",
                  "dest": [
                    {
                      "extension": "stt"
                    }
                  ]
                }
              ]
            },
            {
              "extension": "tts",
              "cmd": [
                {
                  "name": "flush",
                  "dest": [
                    {
                      "extension": "avatar"
                    }
                  ]
                }
              ],
              "audio_frame": [
                {
                  "name": "pcm_frame",
                  "dest": [
                    {
                      "extension": "avatar"
                    }
                  ]
                }
              ],
              "data": [
                {
                  "name": "tts_audio_start",
                  "dest": [
                    {
                      "extension": "avatar"
                    },
                    {
                      "extension": "thymia_analyzer"
                    }
                  ]
                },
                {
                  "name": "tts_audio_end",
                  "dest": [
                    {
                      "extension": "avatar"
                    },
                    {
                      "extension": "thymia_analyzer"
                    }
                  ]
                }
              ]
            }
          ]
        }
      },
      {
        "name": "nova3_apollo_cartesia_heygen",
        "auto_start": false,
        "graph": {
          "nodes": [
            {
              "type": "extension",
              "name": "agora_rtc",
              "addon": "agora_rtc",
              "extension_group": "default",
              "property": {
                "app_id": "${env:AGORA_APP_ID}",
                "app_certificate": "${env:AGORA_APP_CERTIFICATE|}",
                "channel": "",
                "stream_id": 0,
                "remote_stream_id": 182837,
                "subscribe_audio": true,
                "publish_audio": true,
                "publish_data": true,
                "enable_agora_asr": false
              }
            },
            {
              "type": "extension",
              "name": "stt",
              "addon": "deepgram_ws_asr_python",
              "extension_group": "stt",
              "property": {
                "params": {
                  "api_key": "${env:DEEPGRAM_API_KEY}",
                  "url": "wss://api.deepgram.com/v1/listen",
                  "model": "nova-3",
                  "language": "en-US",
                  "endpointing": 300,
                  "utterance_end_ms": 1000
                }
              }
            },
            {
              "type": "extension",
              "name": "llm",
              "addon": "openai_llm2_python",
              "extension_group": "chatgpt",
              "property": {
                "base_url": "https://api.openai.com/v1",
                "api_key": "${env:OPENAI_API_KEY}",
                "frequency_penalty": 0.9,
                "model": "${env:OPENAI_MODEL}",
                "max_tokens": 200,
                "prompt": "You are a mental wellness research assistant conducting a demonstration. Guide the conversation efficiently:\n\n1. When user provides their name, sex, and year of birth, acknowledge warmly in 1-2 sentences and ask about their day. Keep this response SHORT and conversational. DO NOT call set_user_info yet.\n2. On your NEXT response (after they answer about their day), silently call set_user_info(name, year_of_birth, birth_sex) in the background while continuing the conversation. This is REQUIRED before analysis can start.\n3. Ask: 'Tell me about your interests and hobbies.' (wait for response - aim for 30+ seconds total speech)\n4. CRITICAL: Before moving to reading phase or saying you're processing, you MUST call check_phase_progress to verify enough speech has been collected. If phase_complete=false, ask another question to gather more speech. Only proceed when phase_complete=true.\n5. Once check_phase_progress confirms phase_complete=true, say: 'Thank you. Now please read aloud anything you can see around you - a book, article, or text on your screen - for about 30 seconds.'\n6. CRITICAL: After user finishes reading, you MUST call check_phase_progress again before saying you're processing. If reading_phase_complete=false, ask them to continue reading. Only when reading_phase_complete=true, say: 'Perfect. I'm processing your responses now, this will take about a minute.'\n7. IMPORTANT: You will receive TWO separate [SYSTEM ALERT] messages - one for wellness metrics, then another for clinical indicators. WAIT for each alert before announcing.\n8. When you receive '[SYSTEM ALERT] Wellness metrics ready', call get_wellness_metrics and announce the 5 wellness metrics (stress, distress, burnout, fatigue, low_self_esteem). Values are PERCENTAGES 0-100. DO NOT use markdown formatting (no **, *, _, etc.) - use plain numbered lists only. After announcing, IMMEDIATELY call confirm_announcement with phase='hellos'. Then WAIT - do NOT proactively call get_wellness_metrics again.\n9. Later, you will receive '[SYSTEM ALERT] Clinical indicators ready'. Only then should you call get_wellness_metrics again and announce the 2 clinical indicators (depression, anxiety). After announcing, IMMEDIATELY call confirm_announcement with phase='apollo'.\n10. Frame as research indicators, not clinical diagnosis\n11. Thank them for participating in the demonstration\n\nNote: Keep all responses concise. We need 60 seconds total speech (30s for mood/interests + 30s for reading). The first 30s is used for both Hellos and Apollo mood analysis. The next 30s is used for Apollo reading analysis.",
                "proxy_url": "${env:OPENAI_PROXY_URL|}",
                "greeting": "Hi there! I would like to talk to you for a couple of minutes and use your voice to predict your mood and energy levels including any depression, anxiety, stress, and fatigue. Nothing will be recorded and this is purely a demonstration of what is possible now that we have trained our models with many hours of professionally labelled data. Please begin by telling me your name, sex and year of birth.",
                "max_memory_length": 10
              }
            },
            {
              "type": "extension",
              "name": "tts",
              "addon": "cartesia_tts",
              "extension_group": "tts",
              "property": {
                "dump": false,
                "dump_path": "./",
                "params": {
                  "api_key": "${env:CARTESIA_TTS_KEY}",
                  "model_id": "sonic-3",
                  "voice": {
                    "mode": "id",
                    "id": "71a7ad14-091c-4e8e-a314-022ece01c121"
                  },
                  "generation_config": {
                    "speed": 1
                  },
                  "output_format": {
                    "container": "raw",
                    "sample_rate": 44100
                  },
                  "language": "en"
                }
              }
            },
            {
              "type": "extension",
              "name": "thymia_analyzer",
              "addon": "thymia_analyzer_python",
              "extension_group": "default",
              "property": {
                "api_key": "${env:THYMIA_API_KEY}",
                "min_speech_duration": 30,
                "analysis_mode": "demo_dual",
                "apollo_mood_duration": 30,
                "apollo_read_duration": 30
              }
            },
            {
              "type": "extension",
              "name": "avatar",
              "addon": "heygen_avatar_python",
              "extension_group": "default",
              "property": {
                "heygen_api_key": "${env:HEYGEN_API_KEY|}",
                "agora_appid": "${env:AGORA_APP_ID}",
                "agora_appcert": "${env:AGORA_APP_CERTIFICATE|}",
                "channel": "",
                "agora_avatar_uid": 12345,
                "input_audio_sample_rate": 44100,
                "avatar_name": "Katya_Chair_Sitting_public"
              }
            },
            {
              "type": "extension",
              "name": "main_control",
              "addon": "main_python",
              "extension_group": "control",
              "property": {
                "greeting": "Hi there! I would like to talk to you for a couple of minutes and use your voice to predict your mood and energy levels including any depression, anxiety, stress, and fatigue. Nothing will be recorded and this is purely a demonstration of what is possible now that we have trained our models with many hours of professionally labelled data. Please begin by telling me your name, sex and year of birth."
              }
            },
            {
              "type": "extension",
              "name": "message_collector",
              "addon": "message_collector2",
              "extension_group": "transcriber",
              "property": {}
            },
            {
              "type": "extension",
              "name": "streamid_adapter",
              "addon": "streamid_adapter",
              "property": {}
            }
          ],
          "connections": [
            {
              "extension": "main_control",
              "cmd": [
                {
                  "names": [
                    "on_user_joined",
                    "on_user_left"
                  ],
                  "source": [
                    {
                      "extension": "agora_rtc"
                    }
                  ]
                },
                {
                  "names": [
                    "tool_register"
                  ],
                  "source": [
                    {
                      "extension": "thymia_analyzer"
                    }
                  ]
                }
              ],
              "data": [
                {
                  "name": "asr_result",
                  "source": [
                    {
                      "extension": "stt"
                    }
                  ]
                },
                {
                  "name": "text_data",
                  "source": [
                    {
                      "extension": "thymia_analyzer"
                    }
                  ]
                }
              ]
            },
            {
              "extension": "agora_rtc",
              "audio_frame": [
                {
                  "name": "pcm_frame",
                  "dest": [
                    {
                      "extension": "streamid_adapter"
                    },
                    {
                      "extension": "thymia_analyzer"
                    }
                  ]
                }
              ],
              "video_frame": [
                {
                  "name": "video_frame",
                  "source": [
                    {
                      "extension": "avatar"
                    }
                  ]
                }
              ],
              "data": [
                {
                  "name": "data",
                  "source": [
                    {
                      "extension": "message_collector"
                    }
                  ]
                }
              ]
            },
            {
              "extension": "streamid_adapter",
              "audio_frame": [
                {
                  "name": "pcm_frame",
                  "dest": [
                    {
                      "extension": "stt"
                    }
                  ]
                }
              ]
            },
            {
              "extension": "avatar",
              "audio_frame": [
                {
                  "name": "pcm_frame",
                  "source": [
                    {
                      "extension": "tts"
                    }
                  ]
                }
              ],
              "data": [
                {
                  "name": "tts_text_input",
                  "source": [
                    {
                      "extension": "main_control"
                    }
                  ]
                },
                {
                  "name": "tts_audio_start",
                  "dest": [
                    {
                      "extension": "thymia_analyzer"
                    }
                  ]
                },
                {
                  "name": "tts_audio_end",
                  "dest": [
                    {
                      "extension": "thymia_analyzer"
                    }
                  ]
                }
              ]
            }
          ]
        }
      },
      {
        "name": "nova3_apollo_cartesia_anam",
        "auto_start": false,
        "graph": {
          "nodes": [
            {
              "type": "extension",
              "name": "agora_rtc",
              "addon": "agora_rtc",
              "extension_group": "default",
              "property": {
                "app_id": "${env:AGORA_APP_ID}",
                "app_certificate": "${env:AGORA_APP_CERTIFICATE|}",
                "channel": "",
                "stream_id": 0,
                "remote_stream_id": 182837,
                "subscribe_audio": true,
                "publish_audio": true,
                "publish_data": true,
                "enable_agora_asr": false
              }
            },
            {
              "type": "extension",
              "name": "stt",
              "addon": "deepgram_ws_asr_python",
              "extension_group": "stt",
              "property": {
                "params": {
                  "api_key": "${env:DEEPGRAM_API_KEY}",
                  "url": "wss://api.deepgram.com/v1/listen",
                  "model": "nova-3",
                  "language": "en-US",
                  "endpointing": 300,
                  "utterance_end_ms": 1000
                }
              }
            },
            {
              "type": "extension",
              "name": "llm",
              "addon": "openai_llm2_python",
              "extension_group": "chatgpt",
              "property": {
                "base_url": "https://api.openai.com/v1",
                "api_key": "${env:OPENAI_API_KEY}",
                "frequency_penalty": 0.9,
                "model": "${env:OPENAI_MODEL}",
                "max_tokens": 200,
                "prompt": "You are a mental wellness research assistant conducting a demonstration. Guide the conversation efficiently:\n\n1. When user provides their name, sex, and year of birth, acknowledge warmly in 1-2 sentences and ask about their day. Keep this response SHORT and conversational. DO NOT call set_user_info yet.\n2. On your NEXT response (after they answer about their day), silently call set_user_info(name, year_of_birth, birth_sex) in the background while continuing the conversation. This is REQUIRED before analysis can start.\n3. Ask: 'Tell me about your interests and hobbies.' (wait for response - aim for 30+ seconds total speech)\n4. CRITICAL: Before moving to reading phase or saying you're processing, you MUST call check_phase_progress to verify enough speech has been collected. If phase_complete=false, ask another question to gather more speech. Only proceed when phase_complete=true.\n5. Once check_phase_progress confirms phase_complete=true, say: 'Thank you. Now please read aloud anything you can see around you - a book, article, or text on your screen - for about 30 seconds.'\n6. CRITICAL: After user finishes reading, you MUST call check_phase_progress again before saying you're processing. If reading_phase_complete=false, ask them to continue reading. Only when reading_phase_complete=true, say: 'Perfect. I'm processing your responses now, this will take about a minute.'\n7. IMPORTANT: You will receive TWO separate [SYSTEM ALERT] messages - one for wellness metrics, then another for clinical indicators. WAIT for each alert before announcing.\n8. When you receive '[SYSTEM ALERT] Wellness metrics ready', call get_wellness_metrics and announce the 5 wellness metrics (stress, distress, burnout, fatigue, low_self_esteem). Values are PERCENTAGES 0-100. DO NOT use markdown formatting (no **, *, _, etc.) - use plain numbered lists only. After announcing, IMMEDIATELY call confirm_announcement with phase='hellos'. Then WAIT - do NOT proactively call get_wellness_metrics again.\n9. Later, you will receive '[SYSTEM ALERT] Clinical indicators ready'. Only then should you call get_wellness_metrics again and announce the 2 clinical indicators (depression, anxiety). After announcing, IMMEDIATELY call confirm_announcement with phase='apollo'.\n10. Frame as research indicators, not clinical diagnosis\n11. Thank them for participating in the demonstration\n\nNote: Keep all responses concise. We need 60 seconds total speech (30s for mood/interests + 30s for reading). The first 30s is used for both Hellos and Apollo mood analysis. The next 30s is used for Apollo reading analysis.",
                "proxy_url": "${env:OPENAI_PROXY_URL|}",
                "greeting": "Hi there! I would like to talk to you for a couple of minutes and use your voice to predict your mood and energy levels including any depression, anxiety, stress, and fatigue. Nothing will be recorded and this is purely a demonstration of what is possible now that we have trained our models with many hours of professionally labelled data. Please begin by telling me your name, sex and year of birth.",
                "max_memory_length": 10
              }
            },
            {
              "type": "extension",
              "name": "tts",
              "addon": "cartesia_tts",
              "extension_group": "tts",
              "property": {
                "dump": false,
                "dump_path": "./",
                "params": {
                  "api_key": "${env:CARTESIA_TTS_KEY}",
                  "model_id": "sonic-3",
                  "voice": {
                    "mode": "id",
                    "id": "71a7ad14-091c-4e8e-a314-022ece01c121"
                  },
                  "generation_config": {
                    "speed": 1
                  },
                  "output_format": {
                    "container": "raw",
                    "sample_rate": 44100
                  },
                  "language": "en"
                }
              }
            },
            {
              "type": "extension",
              "name": "thymia_analyzer",
              "addon": "thymia_analyzer_python",
              "extension_group": "default",
              "property": {
                "api_key": "${env:THYMIA_API_KEY}",
                "min_speech_duration": 30,
                "analysis_mode": "demo_dual",
                "apollo_mood_duration": 30,
                "apollo_read_duration": 30
              }
            },
            {
              "type": "extension",
              "name": "avatar",
              "addon": "anam_avatar_python",
              "extension_group": "default",
              "property": {
                "anam_api_key": "${env:ANAM_API_KEY}",
                "anam_base_url": "https://anam-lab-git-feat-agora-anam-20452f3b.vercel.app/v1",
                "anam_avatar_id": "edf6fdcb-acab-44b8-b974-ded72665ee26",
                "anam_cluster": "dev-eu",
                "anam_pod": "",
                "agora_appid": "${env:AGORA_APP_ID}",
                "agora_appcert": "${env:AGORA_APP_CERTIFICATE|}",
                "channel": "",
                "agora_video_uid": 123,
                "input_audio_sample_rate": 44100,
                "quality": "${env:VIDEO_QUALITY|high}",
                "video_encoding": "${env:VIDEO_ENCODING|H264}",
                "enable_string_uid": false,
                "activity_idle_timeout": 120
              }
            },
            {
              "type": "extension",
              "name": "main_control",
              "addon": "main_python",
              "extension_group": "control",
              "property": {
                "greeting": "Hi there! I would like to talk to you for a couple of minutes and use your voice to predict your mood and energy levels including any depression, anxiety, stress, and fatigue. Nothing will be recorded and this is purely a demonstration of what is possible now that we have trained our models with many hours of professionally labelled data. Please begin by telling me your name, sex and year of birth."
              }
            },
            {
              "type": "extension",
              "name": "message_collector",
              "addon": "message_collector2",
              "extension_group": "transcriber",
              "property": {}
            },
            {
              "type": "extension",
              "name": "streamid_adapter",
              "addon": "streamid_adapter",
              "property": {}
            }
          ],
          "connections": [
            {
              "extension": "main_control",
              "cmd": [
                {
                  "names": [
                    "on_user_joined",
                    "on_user_left"
                  ],
                  "source": [
                    {
                      "extension": "agora_rtc"
                    }
                  ]
                },
                {
                  "names": [
                    "tool_register"
                  ],
                  "source": [
                    {
                      "extension": "thymia_analyzer"
                    }
                  ]
                }
              ],
              "data": [
                {
                  "name": "asr_result",
                  "source": [
                    {
                      "extension": "stt"
                    }
                  ]
                },
                {
                  "name": "text_data",
                  "source": [
                    {
                      "extension": "thymia_analyzer"
                    }
                  ]
                }
              ]
            },
            {
              "extension": "agora_rtc",
              "audio_frame": [
                {
                  "name": "pcm_frame",
                  "dest": [
                    {
                      "extension": "streamid_adapter"
                    },
                    {
                      "extension": "thymia_analyzer"
                    }
                  ]
                }
              ],
              "data": [
                {
                  "name": "data",
                  "source": [
                    {
                      "extension": "message_collector"
                    }
                  ]
                }
              ]
            },
            {
              "extension": "streamid_adapter",
              "audio_frame": [
                {
                  "name": "pcm_frame",
                  "dest": [
                    {
                      "extension": "stt"
                    }
                  ]
                }
              ]
            },
            {
              "extension": "stt",
              "data": [
                {
                  "name": "text_data",
                  "dest": [
                    {
                      "extension": "llm"
                    }
                  ]
                }
              ]
            },
            {
              "extension": "llm",
              "audio_frame": [
                {
                  "name": "pcm_frame",
                  "dest": [
                    {
                      "extension": "avatar"
                    }
                  ]
                }
              ],
              "cmd": [
                {
                  "name": "flush",
                  "dest": [
                    {
                      "extension": "avatar"
                    }
                  ]
                }
              ],
              "data": [
                {
                  "name": "text_data",
                  "dest": [
                    {
                      "extension": "message_collector"
                    }
                  ]
                }
              ]
            },
            {
              "extension": "tts",
              "audio_frame": [
                {
                  "name": "pcm_frame",
                  "dest": [
                    {
                      "extension": "avatar"
                    }
                  ]
                }
              ],
              "cmd": [
                {
                  "name": "flush",
                  "dest": [
                    {
                      "extension": "avatar"
                    }
                  ]
                }
              ]
            }
          ]
        }
      },
      {
        "name": "flux_apollo_cartesia_anam",
        "auto_start": false,
        "graph": {
          "nodes": [
            {
              "type": "extension",
              "name": "agora_rtc",
              "addon": "agora_rtc",
              "extension_group": "default",
              "property": {
                "app_id": "${env:AGORA_APP_ID}",
                "app_certificate": "${env:AGORA_APP_CERTIFICATE|}",
                "channel": "",
                "stream_id": 0,
                "remote_stream_id": 182837,
                "subscribe_audio": true,
                "publish_audio": true,
                "publish_data": true,
                "enable_agora_asr": false
              }
            },
            {
              "type": "extension",
              "name": "stt",
              "addon": "deepgram_ws_asr_python",
              "extension_group": "stt",
              "property": {
                "params": {
                  "api_key": "${env:DEEPGRAM_API_KEY}",
                  "url": "wss://api.deepgram.com/v2/listen",
                  "model": "flux-general-en",
                  "language": "en-US",
                  "interim_results": true,
                  "eot_threshold": 0.9,
                  "eot_timeout_ms": 2000,
                  "min_interim_confidence": 0.75
                }
              }
            },
            {
              "type": "extension",
              "name": "llm",
              "addon": "openai_llm2_python",
              "extension_group": "chatgpt",
              "property": {
                "base_url": "https://api.openai.com/v1",
                "api_key": "${env:OPENAI_API_KEY}",
                "frequency_penalty": 0.9,
                "model": "${env:OPENAI_MODEL}",
                "max_tokens": 200,
                "prompt": "You are a mental wellness research assistant conducting a demonstration. Guide the conversation efficiently:\n\n1. When user provides their name, sex, and year of birth, acknowledge warmly in 1-2 sentences and ask about their day. Keep this response SHORT and conversational. DO NOT call set_user_info yet.\n2. On your NEXT response (after they answer about their day), silently call set_user_info(name, year_of_birth, birth_sex) in the background while continuing the conversation. This is REQUIRED before analysis can start.\n3. Ask: 'Tell me about your interests and hobbies.' (wait for response - aim for 30+ seconds total speech)\n4. CRITICAL: Before moving to reading phase or saying you're processing, you MUST call check_phase_progress to verify enough speech has been collected. If phase_complete=false, ask another question to gather more speech. Only proceed when phase_complete=true.\n5. Once check_phase_progress confirms phase_complete=true, say: 'Thank you. Now please read aloud anything you can see around you - a book, article, or text on your screen - for about 30 seconds.'\n6. CRITICAL: After user finishes reading, you MUST call check_phase_progress again before saying you're processing. If reading_phase_complete=false, ask them to continue reading. Only when reading_phase_complete=true, say: 'Perfect. I'm processing your responses now, this will take about a minute.'\n7. IMPORTANT: You will receive TWO separate [SYSTEM ALERT] messages - one for wellness metrics, then another for clinical indicators. WAIT for each alert before announcing.\n8. When you receive '[SYSTEM ALERT] Wellness metrics ready', call get_wellness_metrics and announce the 5 wellness metrics (stress, distress, burnout, fatigue, low_self_esteem). Values are PERCENTAGES 0-100. DO NOT use markdown formatting (no **, *, _, etc.) - use plain numbered lists only. After announcing, IMMEDIATELY call confirm_announcement with phase='hellos'. Then WAIT - do NOT proactively call get_wellness_metrics again.\n9. Later, you will receive '[SYSTEM ALERT] Clinical indicators ready'. Only then should you call get_wellness_metrics again and announce the 2 clinical indicators (depression, anxiety). After announcing, IMMEDIATELY call confirm_announcement with phase='apollo'.\n10. Frame as research indicators, not clinical diagnosis\n11. Thank them for participating in the demonstration\n\nNote: Keep all responses concise. We need 60 seconds total speech (30s for mood/interests + 30s for reading). The first 30s is used for both Hellos and Apollo mood analysis. The next 30s is used for Apollo reading analysis.",
                "proxy_url": "${env:OPENAI_PROXY_URL|}",
                "greeting": "Hi there! I would like to talk to you for a couple of minutes and use your voice to predict your mood and energy levels including any depression, anxiety, stress, and fatigue. Nothing will be recorded and this is purely a demonstration of what is possible now that we have trained our models with many hours of professionally labelled data. Please begin by telling me your name, sex and year of birth.",
                "max_memory_length": 10
              }
            },
            {
              "type": "extension",
              "name": "tts",
              "addon": "cartesia_tts",
              "extension_group": "tts",
              "property": {
                "dump": false,
                "dump_path": "./",
                "params": {
                  "api_key": "${env:CARTESIA_TTS_KEY}",
                  "model_id": "sonic-3",
                  "voice": {
                    "mode": "id",
                    "id": "71a7ad14-091c-4e8e-a314-022ece01c121"
                  },
                  "generation_config": {
                    "speed": 1.0
                  },
                  "output_format": {
                    "container": "raw",
                    "sample_rate": 44100
                  },
                  "language": "en"
                }
              }
            },
            {
              "type": "extension",
              "name": "thymia_analyzer",
              "addon": "thymia_analyzer_python",
              "extension_group": "default",
              "property": {
                "api_key": "${env:THYMIA_API_KEY}",
                "min_speech_duration": 30.0,
                "analysis_mode": "demo_dual",
                "apollo_mood_duration": 30.0,
                "apollo_read_duration": 30.0
              }
            },
            {
              "type": "extension",
              "name": "avatar",
              "addon": "anam_avatar_python",
              "extension_group": "default",
              "property": {
                "anam_api_key": "${env:ANAM_API_KEY}",
                "anam_base_url": "https://anam-lab-git-feat-agora-anam-20452f3b.vercel.app/v1",
                "anam_avatar_id": "edf6fdcb-acab-44b8-b974-ded72665ee26",
                "anam_cluster": "dev-eu",
                "anam_pod": "",
                "agora_appid": "${env:AGORA_APP_ID}",
                "agora_appcert": "${env:AGORA_APP_CERTIFICATE|}",
                "channel": "",
                "agora_video_uid": 123,
                "input_audio_sample_rate": 44100,
                "quality": "${env:VIDEO_QUALITY|high}",
                "video_encoding": "${env:VIDEO_ENCODING|H264}",
                "enable_string_uid": false,
                "activity_idle_timeout": 120
              }
            },
            {
              "type": "extension",
              "name": "main_control",
              "addon": "main_python",
              "extension_group": "control",
              "property": {
                "greeting": "Hi there! I would like to talk to you for a couple of minutes and use your voice to predict your mood and energy levels including any depression, anxiety, stress, and fatigue. Nothing will be recorded and this is purely a demonstration of what is possible now that we have trained our models with many hours of professionally labelled data. Please begin by telling me your name, sex and year of birth."
              }
            },
            {
              "type": "extension",
              "name": "message_collector",
              "addon": "message_collector2",
              "extension_group": "transcriber",
              "property": {}
            },
            {
              "type": "extension",
              "name": "streamid_adapter",
              "addon": "streamid_adapter",
              "property": {}
            }
          ],
          "connections": [
            {
              "extension": "main_control",
              "cmd": [
                {
                  "names": [
                    "on_user_joined",
                    "on_user_left"
                  ],
                  "source": [
                    {
                      "extension": "agora_rtc"
                    }
                  ]
                },
                {
                  "names": [
                    "tool_register"
                  ],
                  "source": [
                    {
                      "extension": "thymia_analyzer"
                    }
                  ]
                }
              ],
              "data": [
                {
                  "name": "asr_result",
                  "source": [
                    {
                      "extension": "stt"
                    }
                  ]
                },
                {
                  "name": "text_data",
                  "source": [
                    {
                      "extension": "thymia_analyzer"
                    }
                  ]
                }
              ]
            },
            {
              "extension": "agora_rtc",
              "audio_frame": [
                {
                  "name": "pcm_frame",
                  "dest": [
                    {
                      "extension": "streamid_adapter"
                    },
                    {
                      "extension": "thymia_analyzer"
                    }
                  ]
                }
              ],
              "data": [
                {
                  "name": "data",
                  "source": [
                    {
                      "extension": "message_collector"
                    }
                  ]
                }
              ]
            },
            {
              "extension": "streamid_adapter",
              "audio_frame": [
                {
                  "name": "pcm_frame",
                  "dest": [
                    {
                      "extension": "stt"
                    }
                  ]
                }
              ]
            },
            {
              "extension": "stt",
              "data": [
                {
                  "name": "text_data",
                  "dest": [
                    {
                      "extension": "llm"
                    }
                  ]
                }
              ]
            },
            {
              "extension": "llm",
              "audio_frame": [
                {
                  "name": "pcm_frame",
                  "dest": [
                    {
                      "extension": "avatar"
                    }
                  ]
                }
              ],
              "cmd": [
                {
                  "name": "flush",
                  "dest": [
                    {
                      "extension": "avatar"
                    }
                  ]
                }
              ],
              "data": [
                {
                  "name": "text_data",
                  "dest": [
                    {
                      "extension": "message_collector"
                    }
                  ]
                }
              ]
            },
            {
              "extension": "tts",
              "audio_frame": [
                {
                  "name": "pcm_frame",
                  "dest": [
                    {
                      "extension": "avatar"
                    }
                  ]
                }
              ],
              "cmd": [
                {
                  "name": "flush",
                  "dest": [
                    {
                      "extension": "avatar"
                    }
                  ]
                }
              ]
            }
          ]
        }
      },
      {
        "name": "voice_assistant_anam",
        "auto_start": false,
        "graph": {
          "nodes": [
            {
              "type": "extension",
              "name": "agora_rtc",
              "addon": "agora_rtc",
              "extension_group": "default",
              "property": {
                "app_id": "${env:AGORA_APP_ID}",
                "app_certificate": "${env:AGORA_APP_CERTIFICATE|}",
                "channel": "",
                "stream_id": 0,
                "remote_stream_id": 123,
                "subscribe_audio": true,
                "publish_audio": true,
                "publish_data": true,
                "enable_agora_asr": false
              }
            },
            {
              "type": "extension",
              "name": "stt",
              "addon": "deepgram_ws_asr_python",
              "extension_group": "default"
            },
            {
              "type": "extension",
              "name": "llm",
              "addon": "openai_llm2_python",
              "extension_group": "default"
            },
            {
              "type": "extension",
              "name": "avatar",
              "addon": "anam_avatar_python",
              "extension_group": "default",
              "property": {
                "anam_api_key": "${env:ANAM_API_KEY}",
                "anam_base_url": "https://anam-lab-git-feat-agora-anam-20452f3b.vercel.app/v1",
                "anam_avatar_id": "edf6fdcb-acab-44b8-b974-ded72665ee26",
                "anam_cluster": "dev-eu",
                "anam_pod": "",
                "agora_appid": "${env:AGORA_APP_ID}",
                "agora_appcert": "${env:AGORA_APP_CERTIFICATE|}",
                "channel": "",
                "agora_video_uid": 123,
                "input_audio_sample_rate": 48000,
                "quality": "${env:VIDEO_QUALITY|high}",
                "video_encoding": "${env:VIDEO_ENCODING|H264}",
                "enable_string_uid": false,
                "activity_idle_timeout": 120
              }
            }
          ],
          "connections": [
            {
              "extension": "agora_rtc",
              "audio_frame": [
                {
                  "name": "pcm_frame",
                  "dest": [
                    {
                      "extension": "stt"
                    }
                  ]
                }
              ]
            },
            {
              "extension": "stt",
              "data": [
                {
                  "name": "text_data",
                  "dest": [
                    {
                      "extension": "llm"
                    }
                  ]
                }
              ]
            },
            {
              "extension": "llm",
              "audio_frame": [
                {
                  "name": "pcm_frame",
                  "dest": [
                    {
                      "extension": "avatar"
                    }
                  ]
                }
              ],
              "cmd": [
                {
                  "name": "flush",
                  "dest": [
                    {
                      "extension": "avatar"
                    }
                  ]
                }
              ]
            }
          ]
        }
      }
    ]
  }
}